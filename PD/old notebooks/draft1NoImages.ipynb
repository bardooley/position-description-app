{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import LETTER\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image\n",
    "from reportlab.lib.enums import TA_CENTER, TA_JUSTIFY\n",
    "from reportlab.lib.units import inch\n",
    "import requests\n",
    "import os\n",
    "from PIL import Image as PILImage\n",
    "from io import BytesIO\n",
    "import json\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from PIL import Image as PILImage\n",
    "from io import BytesIO\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You entered:\n",
      "School: Duxbury High School\n",
      "Position: Athletic Director\n",
      "Notes file: duxbury_ad_notes.txt\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user for school information\n",
    "#school_name = input(\"Enter the school name: \")\n",
    "#position_name = input(\"Enter the position name: \")\n",
    "#notes_file = input(\"Enter the name of the file containing your notes on the school: \")\n",
    "\n",
    "\n",
    "school_name = \"Duxbury High School\"\n",
    "position_name = \"Athletic Director\"\n",
    "notes_file = \"duxbury_ad_notes.txt\"\n",
    "\n",
    "print(f\"\\nYou entered:\")\n",
    "print(f\"School: {school_name}\")\n",
    "print(f\"Position: {position_name}\")\n",
    "print(f\"Notes file: {notes_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully read notes from duxbury_ad_notes.txt\n",
      "Notes preview: \n",
      "Duxbury High School - Athletic Director Position Notes\n",
      "--------------------------------------------...\n"
     ]
    }
   ],
   "source": [
    "# Read the contents of the notes file\n",
    "try:\n",
    "    with open(notes_file, 'r') as file:\n",
    "        notes_content = file.read()\n",
    "    print(f\"\\nSuccessfully read notes from {notes_file}\")\n",
    "    print(f\"Notes preview: {notes_content[:100]}...\" if len(notes_content) > 100 else f\"Notes: {notes_content}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nError: The file '{notes_file}' was not found.\")\n",
    "    notes_content = \"\"\n",
    "except Exception as e:\n",
    "    print(f\"\\nError reading the file: {str(e)}\")\n",
    "    notes_content = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for information about Duxbury High School...\n",
      "\n",
      "Research Results:\n",
      "Duxbury High School is a public secondary school located in Duxbury, Massachusetts, United States. It serves students in grades 9 through 12 and is part of the Duxbury Public Schools district. \n",
      "\n",
      "**Location:**  \n",
      "Duxbury High School is situated in the town of Duxbury, approximately 25 miles south of Boston, along the Atlantic coast.\n",
      "\n",
      "**Size:**  \n",
      "The school has an enrollment of roughly 800 to 900 students, offering a close-knit community environment with a variety of academic and extracurricular options.\n",
      "\n",
      "**Academic Programs:**  \n",
      "Duxbury High School provides a comprehensive curriculum including core subjects such as English, Math, Science, and Social Studies, as well as numerous electives. It offers Advanced Placement (AP) courses, honors classes, and opportunities for college credit through partnerships with local colleges. The school emphasizes academic excellence, college readiness, and personalized learning.\n",
      "\n",
      "**Notable Features:**  \n",
      "- A strong tradition of academic achievement and extracurricular involvement.  \n",
      "- Robust arts programs, including music, theater, and visual arts.  \n",
      "- A wide range of athletic teams competing in various sports.  \n",
      "- Various clubs and activities that promote community engagement and leadership.  \n",
      "- Facilities include modern classrooms, athletic fields, a theater, and dedicated arts spaces.\n",
      "\n",
      "Duxbury High School is known for fostering a supportive environment that encourages student growth both academically and socially.\n"
     ]
    }
   ],
   "source": [
    "#do online research on the school\n",
    "def search_school_info(school_name):\n",
    "    try:\n",
    "        # Create a completion that searches for information about the school\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-nano\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides factual information.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Please provide some basic information about {school_name}. Include details about location, size, academic programs, and any notable features.\"}\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        # Extract the information from the response\n",
    "        school_info = response.choices[0].message.content\n",
    "        return school_info\n",
    "    except Exception as e:\n",
    "        return f\"Error searching for school information: {str(e)}\"\n",
    "\n",
    "# Search for information about the school entered by the user\n",
    "if school_name:\n",
    "    print(f\"\\nSearching for information about {school_name}...\")\n",
    "    school_research = search_school_info(school_name)\n",
    "    print(\"\\nResearch Results:\")\n",
    "    print(school_research)\n",
    "else:\n",
    "    school_research = \"No school name provided for research.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_images_from_site(url, max_images=3):\n",
    "    \"\"\"\n",
    "    Scrapes images from a given website URL.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL of the website to scrape\n",
    "        max_images (int): Maximum number of images to return\n",
    "    \n",
    "    Returns:\n",
    "        list: List of image URLs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        img_tags = soup.find_all('img')\n",
    "        \n",
    "        # Extract image URLs\n",
    "        img_urls = []\n",
    "        for img in img_tags:\n",
    "            src = img.get('src')\n",
    "            if src:\n",
    "                # Convert relative URLs to absolute URLs\n",
    "                absolute_url = urljoin(url, src)\n",
    "                if absolute_url.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                    img_urls.append(absolute_url)\n",
    "        \n",
    "        return img_urls[:max_images]\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping website: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_images_to_description(description, images):\n",
    "    \"\"\"\n",
    "    Adds image placeholders to the position description text.\n",
    "    \n",
    "    Args:\n",
    "        description (str): The position description text\n",
    "        images (list): List of dictionaries containing image information\n",
    "    \n",
    "    Returns:\n",
    "        str: The modified description with image placeholders\n",
    "    \"\"\"\n",
    "    # Add image placeholders at appropriate locations\n",
    "    # For example, after the School Overview section\n",
    "    sections = description.split('###')\n",
    "    modified_sections = []\n",
    "    \n",
    "    for i, section in enumerate(sections):\n",
    "        modified_sections.append(section)\n",
    "        if i == 1:  # After School Overview\n",
    "            for img in images:\n",
    "                if 'caption' in img:\n",
    "                    modified_sections.append(f\"\\n![{img['caption']}]({img['path']})\\n\")\n",
    "                else:\n",
    "                    modified_sections.append(f\"\\n![Image]({img['path']})\\n\")\n",
    "    \n",
    "    return '###'.join(modified_sections)\n",
    "\n",
    "def search_school_images(school_name):\n",
    "    try:\n",
    "        # First, try to find the school's official website\n",
    "        website_query = f\"{school_name} official website\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-nano\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that finds school websites. Return only the official school website URL.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Please provide the official website URL for {school_name}. Only return the URL, nothing else.\"}\n",
    "            ],\n",
    "            max_tokens=100\n",
    "        )\n",
    "        \n",
    "        school_website = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Try to scrape images from the official website first\n",
    "        if school_website:\n",
    "            print(f\"Found school website: {school_website}\")\n",
    "            img_urls = scrape_images_from_site(school_website)\n",
    "            if img_urls:\n",
    "                return img_urls\n",
    "        \n",
    "        # If no images found from official website, try a general search\n",
    "        print(\"No images found on official website, trying general search...\")\n",
    "        search_query = f\"{school_name} high school building campus exterior\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-nano\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that finds school images. Return only direct image URLs that are likely to be accessible.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Please provide 3 direct image URLs that show {search_query}. Only return the URLs, one per line, nothing else. Make sure the URLs end in .jpg, .jpeg, or .png and are from reliable sources like the school's official website, local news sites, or educational websites.\"}\n",
    "            ],\n",
    "            max_tokens=300\n",
    "        )\n",
    "        \n",
    "        # Parse the response to get image URLs\n",
    "        urls = [url.strip() for url in response.choices[0].message.content.split('\\n') if url.strip()]\n",
    "        \n",
    "        # Filter URLs to ensure they're direct image links\n",
    "        valid_urls = []\n",
    "        for url in urls:\n",
    "            if url.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                valid_urls.append(url)\n",
    "        \n",
    "        return valid_urls[:3]  # Return up to 3 valid images\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error searching for images: {str(e)}\")\n",
    "        return []  \n",
    "  \n",
    "def download_and_process_image(image_url, output_dir, index):\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Download the image with a longer timeout and retry mechanism\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "            \"Accept\": \"image/webp,image/apng,image/*,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "            \"Referer\": \"https://www.google.com/\"\n",
    "        }\n",
    "        \n",
    "        # Try to download the image with retries\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(image_url, headers=headers, timeout=10)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                # Verify that the response is actually an image\n",
    "                content_type = response.headers.get('content-type', '')\n",
    "                if not content_type.startswith('image/'):\n",
    "                    raise ValueError(f\"URL did not return an image (content-type: {content_type})\")\n",
    "                \n",
    "                # Try to open the image to verify it's valid\n",
    "                img = PILImage.open(BytesIO(response.content))\n",
    "                img.verify()  # Verify it's a valid image\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise e\n",
    "                print(f\"Retry {attempt + 1} for {image_url}\")\n",
    "                continue\n",
    "        \n",
    "        # Open and process the image\n",
    "        img = PILImage.open(BytesIO(response.content))\n",
    "        \n",
    "        # Convert to RGB if necessary\n",
    "        if img.mode in ('RGBA', 'P'):\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        # Calculate new dimensions while maintaining aspect ratio\n",
    "        max_width = 800\n",
    "        max_height = 600\n",
    "        width, height = img.size\n",
    "        \n",
    "        if width > max_width or height > max_height:\n",
    "            ratio = min(max_width/width, max_height/height)\n",
    "            new_width = int(width * ratio)\n",
    "            new_height = int(height * ratio)\n",
    "            img = img.resize((new_width, new_height), PILImage.Resampling.LANCZOS)\n",
    "        \n",
    "        # Save the processed image\n",
    "        output_path = os.path.join(output_dir, f'school_image_{index}.jpg')\n",
    "        img.save(output_path, 'JPEG', quality=85)\n",
    "        \n",
    "        # Return image information\n",
    "        return {\n",
    "            'path': output_path,\n",
    "            'caption': f'Image of {school_name}',\n",
    "            'width': 400,  # Default width in points\n",
    "            'height': 300  # Default height in points\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_url}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "def get_school_images(school_name, output_dir='school_images'):\n",
    "    # Search for images\n",
    "    image_urls = search_school_images(school_name)\n",
    "    \n",
    "    # Download and process images\n",
    "    images = []\n",
    "    for i, url in enumerate(image_urls):\n",
    "        img_info = download_and_process_image(url, output_dir, i)\n",
    "        if img_info:\n",
    "            images.append(img_info)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_position_description(school_name, position_name, client_notes, school_research=None):\n",
    "    \"\"\"\n",
    "    Creates a comprehensive position description based on provided information.\n",
    "    \n",
    "    Args:\n",
    "        school_name (str): The name of the school\n",
    "        position_name (str): The title of the open position\n",
    "        client_notes (str): Notes provided by the client about the position\n",
    "        school_research (str, optional): Additional research about the school\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted position description of approximately 1000 words\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Combine all available information for context\n",
    "        combined_info = f\"\"\"\n",
    "        School Name: {school_name}\n",
    "        Position Name: {position_name}\n",
    "        Client Notes: {client_notes}\n",
    "        \"\"\"\n",
    "        \n",
    "        if school_research:\n",
    "            combined_info += f\"\\nSchool Research: {school_research}\"\n",
    "        \n",
    "        # Generate the position description using the OpenAI API\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-nano\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert HR professional who creates compelling job descriptions. Create a comprehensive, well-structured position description of approximately 1000 words that would be sent to job applicants.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Please create a detailed position description for the following job at an educational institution. Make it approximately 1000 words, professional in tone, and include sections for school overview, role responsibilities, qualifications, benefits, and application process. Here's the information I have:\\n\\n{combined_info}\"}\n",
    "            ],\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        \n",
    "        # Extract and return the position description\n",
    "        position_description = response.choices[0].message.content\n",
    "        return position_description\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error creating position description: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the position description to PDF\n",
    "#position_description = create_position_description(school_name, position_name, notes_content, school_research)\n",
    "def convert_to_pdf(text, output_filename=\"position_description.pdf\", images=None):\n",
    "    \"\"\"\n",
    "    Converts the position description text to a PDF file.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The position description text to convert\n",
    "        output_filename (str): The name of the output PDF file\n",
    "        images (list, optional): List of image information dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        str: A message indicating success or failure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a PDF document\n",
    "        doc = SimpleDocTemplate(output_filename, pagesize=LETTER)\n",
    "        styles = getSampleStyleSheet()\n",
    "        \n",
    "        # Create custom styles\n",
    "        custom_title_style = ParagraphStyle(\n",
    "            name='CustomTitle',\n",
    "            parent=styles['Heading1'],\n",
    "            fontSize=14,\n",
    "            alignment=TA_CENTER,\n",
    "            spaceAfter=12\n",
    "        )\n",
    "        \n",
    "        custom_section_style = ParagraphStyle(\n",
    "            name='CustomSectionHeader',\n",
    "            parent=styles['Heading2'],\n",
    "            fontSize=12,\n",
    "            spaceAfter=6,\n",
    "            spaceBefore=12\n",
    "        )\n",
    "        \n",
    "        custom_normal_style = ParagraphStyle(\n",
    "            name='CustomNormal',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=10,\n",
    "            alignment=TA_JUSTIFY\n",
    "        )\n",
    "        \n",
    "        custom_caption_style = ParagraphStyle(\n",
    "            name='CustomCaption',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=8,\n",
    "            alignment=TA_CENTER,\n",
    "            textColor=colors.gray\n",
    "        )\n",
    "        \n",
    "        # Process the text into paragraphs\n",
    "        story = []\n",
    "        \n",
    "        # Split the text into lines\n",
    "        lines = text.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                story.append(Spacer(1, 6))\n",
    "                continue\n",
    "                \n",
    "            # Determine the style based on the line content\n",
    "            if line.startswith('==='):\n",
    "                continue  # Skip the === lines\n",
    "            elif line.startswith('**Position Title:') or line.startswith('**Location:') or line.startswith('**Application Deadline:') or line.startswith('**Start Date:'):\n",
    "                story.append(Paragraph(line, custom_title_style))\n",
    "            elif line.startswith('###'):\n",
    "                # Section header\n",
    "                header_text = line.replace('###', '').strip()\n",
    "                story.append(Paragraph(header_text, custom_section_style))\n",
    "                \n",
    "                # Add images after School Overview section\n",
    "                if header_text == \"School Overview\" and images:\n",
    "                    for img_info in images:\n",
    "                        try:\n",
    "                            # Add spacing before image\n",
    "                            story.append(Spacer(1, 12))\n",
    "                            \n",
    "                            # Add the image\n",
    "                            img = Image(img_info['path'], width=img_info.get('width', 400), height=img_info.get('height', 300))\n",
    "                            story.append(img)\n",
    "                            \n",
    "                            # Add caption if provided\n",
    "                            if 'caption' in img_info:\n",
    "                                story.append(Spacer(1, 6))\n",
    "                                story.append(Paragraph(img_info['caption'], custom_caption_style))\n",
    "                            \n",
    "                            # Add spacing after image\n",
    "                            story.append(Spacer(1, 12))\n",
    "                        except Exception as e:\n",
    "                            print(f\"Warning: Could not add image {img_info['path']}: {str(e)}\")\n",
    "                \n",
    "            elif line.startswith('**') and line.endswith('**'):\n",
    "                # Subsection header\n",
    "                subsection_text = line.strip('**')\n",
    "                story.append(Paragraph(subsection_text, styles['Heading3']))\n",
    "            elif line.startswith('-'):\n",
    "                # Bullet point\n",
    "                bullet_text = line[1:].strip()\n",
    "                story.append(Paragraph(f\"â€¢ {bullet_text}\", custom_normal_style))\n",
    "            elif line.startswith('---'):\n",
    "                story.append(Spacer(1, 10))\n",
    "            else:\n",
    "                story.append(Paragraph(line, custom_normal_style))\n",
    "        \n",
    "        # Build the PDF\n",
    "        doc.build(story)\n",
    "        \n",
    "        return f\"Successfully created PDF: {output_filename}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error creating PDF: {str(e)}\"\n",
    "# Convert the position description to PDF\n",
    "#pdf_result = convert_to_pdf(position_description)\n",
    "#print(pdf_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"AIzaSyCcSaOIp7HM2LGUMnNwaDvisF2BR0D1HN4\"\n",
    "SEARCH_ENGINE_ID = \"752267de5b1734470\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found school website: https://www.duxbury.k12.ma.us/duxburyhigh\n",
      "No images found on official website, trying general search...\n",
      "Retry 1 for https://www.duxbury.k12.ma.us/cms/lib/MA01001467/Centricity/Domain/27/Duxbury_Exterior.jpg\n",
      "Retry 2 for https://www.duxbury.k12.ma.us/cms/lib/MA01001467/Centricity/Domain/27/Duxbury_Exterior.jpg\n",
      "Error processing image https://www.duxbury.k12.ma.us/cms/lib/MA01001467/Centricity/Domain/27/Duxbury_Exterior.jpg: URL did not return an image (content-type: text/html; charset=utf-8)\n",
      "Retry 1 for https://www.duxburyschoolsinfo.com/images/Duxbury-High-School.jpg\n",
      "Retry 2 for https://www.duxburyschoolsinfo.com/images/Duxbury-High-School.jpg\n",
      "Error processing image https://www.duxburyschoolsinfo.com/images/Duxbury-High-School.jpg: HTTPSConnectionPool(host='www.duxburyschoolsinfo.com', port=443): Max retries exceeded with url: /images/Duxbury-High-School.jpg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x11a28e010>: Failed to resolve 'www.duxburyschoolsinfo.com' ([Errno 8] nodename nor servname provided, or not known)\"))\n",
      "Retry 1 for https://patch.com/img/image-cache/750/0/20210914/102607/9482ca4e4aa6a289aba8707b7d86c52a.jpg\n",
      "Retry 2 for https://patch.com/img/image-cache/750/0/20210914/102607/9482ca4e4aa6a289aba8707b7d86c52a.jpg\n",
      "Error processing image https://patch.com/img/image-cache/750/0/20210914/102607/9482ca4e4aa6a289aba8707b7d86c52a.jpg: 404 Client Error: Not Found for url: https://patch.com/img/image-cache/750/0/20210914/102607/9482ca4e4aa6a289aba8707b7d86c52a.jpg\n",
      "Successfully created PDF: paosition_description.pdf\n"
     ]
    }
   ],
   "source": [
    "# Get images for the school\n",
    "images = get_school_images(school_name)\n",
    "\n",
    "# Generate the position description\n",
    "position_description = create_position_description(school_name, position_name, notes_content, school_research)\n",
    "\n",
    "# Add images to the description\n",
    "modified_description = add_images_to_description(position_description, images)\n",
    "\n",
    "# Convert to PDF with images\n",
    "pdf_result = convert_to_pdf(modified_description, \"paosition_description.pdf\", images)\n",
    "print(pdf_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
